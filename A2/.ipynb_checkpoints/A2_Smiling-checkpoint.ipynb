{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import PIL\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import optim\n",
    "from torchvision.utils import make_grid\n",
    "from pprint import pprint\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# Specify path\n",
    "PATH = ('ADD_PATH/AMLS_20-21_20164490/Datasets/celeba/')\n",
    "\n",
    "\n",
    "#Read in the csv data\n",
    "data = pd.read_csv(PATH + 'labels.csv', delim_whitespace=True)\n",
    "#Create an index\n",
    "data.set_index('img_name', inplace=True)\n",
    "#Instead of values 1,-1 I set 0,1 (replace all -1 with 0)\n",
    "data.replace(-1,0, inplace= True)\n",
    "#Read in to pickle file\n",
    "data.to_pickle(PATH + 'data_pkl.pkl')\n",
    "\n",
    "\n",
    "# for i in ['train', 'valid']:\n",
    "#     os.mkdir(os.path.join(PATH , i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the image files/names\n",
    "filenames = glob.glob(PATH + 'img/*jpg')\n",
    "#Random shuffle so avoid biased training\n",
    "shuffle = np.random.permutation(len(filenames))\n",
    "\n",
    "#Create dataframes\n",
    "training_df = pd.DataFrame()\n",
    "valid_df = pd.DataFrame()\n",
    "\n",
    "#Create seperate folders for training and validation & show progress bar\n",
    "\n",
    "#Split 4,500 image files into training folder\n",
    "for j in tqdm(shuffle[:4500]):\n",
    "    file = filenames[j].split('/')[-1]\n",
    "    training_df = training_df.append( data[data.index == file])\n",
    "    shutil.copy(PATH + 'img/' + file, PATH + 'train/' + file)\n",
    "\n",
    "#Split the remaining 500 image files into validation folder\n",
    "for j in tqdm(shuffle[4500:]):\n",
    "    file = filenames[j].split('/')[-1]\n",
    "    valid_df = valid_df.append(data[data.index == file])\n",
    "    shutil.copy(PATH +'img/'+ file, PATH + 'valid/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create csv and pickle files \n",
    "training_df.to_csv(PATH + 'train.csv')\n",
    "training_df.to_pickle((PATH + 'train.pkl'))\n",
    "\n",
    "valid_df.to_csv(PATH + 'valid.csv')\n",
    "valid_df.to_pickle(PATH + 'valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Outsource computing power to Google servers to avoid computer damage\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Define a class that will load the data when called\n",
    "class Smiling_loader(Dataset):\n",
    "    def __init__(self, df, img_dir, transform = None):\n",
    "        self.dataframe = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.filename = df.index\n",
    "        self.label = df.smiling.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = Image.open(os.path.join(self.img_dir, self.filename[idx]))\n",
    "        label = self.label[idx]\n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            image = self.transform(sample['image'])\n",
    "            sample = {'image': image, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pre-constructed model architectures accessed via urls\n",
    "\n",
    "\n",
    "#Specify model - use vgg19 as it is most accurate\n",
    "model = models.vgg16_bn(pretrained = True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "#Change the final output layer to the number of classes required in our mdoel.\n",
    "n_inputs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 2048), nn.ReLU(), nn.Dropout(0.65),\n",
    "    nn.Linear(2048, 1024), nn.ReLU(),\n",
    "    nn.Dropout(0.6),\n",
    "    nn.Linear(1024, 512), nn.ReLU(),\n",
    "    nn.Linear(512, 2))\n",
    "\n",
    "#Send the Model to the GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class specifying image transforms to improve performancce of model\n",
    "class ImAugtransforms:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "            iaa.Sometimes(0.3, iaa.GaussianBlur(sigma=(0, 2.0))),\n",
    "            iaa.Affine(rotate=(-30, 30), mode='symmetric'),\n",
    "            iaa.Sometimes(0.25,\n",
    "                          iaa.OneOf([iaa.Dropout(p=(0, 0.1)),\n",
    "                                     iaa.CoarseDropout(0.1, size_percent=0.5)])),\n",
    "            iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        return self.aug.augment_image(img)\n",
    "\n",
    "#More transformations\n",
    "train_trns = transforms.Compose([\n",
    "    ImAugtransforms(),\n",
    "    lambda x: PIL.Image.fromarray(x),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    #transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #transforms.RandomGrayscale(p=0.35),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_trns = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the training dataframe\n",
    "training_df = pd.read_pickle(PATH +'train.pkl')\n",
    "training_directory = PATH + 'train/'\n",
    "\n",
    "#Read the validation dataframe\n",
    "valid_df = pd.read_pickle(PATH + 'valid.pkl')\n",
    "validation_directory = PATH + 'valid/'\n",
    "\n",
    "#Use smiling_loader class to call images\n",
    "training_dataloader = Smiling_loader(training_df, training_directory, transform=train_trns)\n",
    "validation_dataloader = Smiling_loader(valid_df, validation_directory, transform=valid_trns)\n",
    "\n",
    "#Plot three images to check transformations\n",
    "plt.imshow(make_grid(training_dataloader[1]['image'].permute(1, 2, 0)))\n",
    "plt.show()\n",
    "plt.imshow(make_grid(training_dataloader[7]['image'].permute(1, 2, 0)))\n",
    "plt.show()\n",
    "plt.imshow(make_grid(training_dataloader[9]['image'].permute(1, 2, 0)))\n",
    "plt.show()\n",
    "print(training_dataloader[1]['label'])\n",
    "print(training_dataloader[7]['label'])\n",
    "print(training_dataloader[9]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify batch size, epochs\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "\n",
    "#Set-up training and validation dataloaders\n",
    "train_dl = DataLoader(training_dataloader, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valid_dl = DataLoader(validation_dataloader, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "#Specify optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.01, momentum=0.9 )\n",
    "\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model function\n",
    "def fit_model(epochs, model, dataloader, phase='training', volatile=False):\n",
    "    pprint(\"Epoch: {}\".format(epochs))\n",
    "\n",
    "    #If training phase, train model\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    #If validation phase, evaluate accuracy and loss of validation image set with trained model\n",
    "    if phase == 'validataion':\n",
    "        model.eval()\n",
    "        volatile = True\n",
    "\n",
    "    running_loss = []\n",
    "    running_acc = []\n",
    "    b = 0\n",
    "    for i, data in enumerate(dataloader):\n",
    "      \n",
    "        inputs, target = data['image'].cuda(), data['label'].cuda()\n",
    "\n",
    "        inputs, target = Variable(inputs), Variable(target)\n",
    "\n",
    "        #If training phase, train the model, evaluate and print the loss and accuracy\n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs.float())\n",
    "\n",
    "        outputs = outputs.to(device=device, dtype=torch.float32)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        acc_ = []\n",
    "\n",
    "        accuracy = (get_num_correct(outputs, target)/BATCH_SIZE)\n",
    "        acc_.append(accuracy)\n",
    "\n",
    "        # print('In Epoch', epochs)\n",
    "        # print('')\n",
    "        # print('predictions', preds)\n",
    "        # print('targets    ', target)\n",
    "        # print('Batch Accuracy is ' + \"{:.2%}\".format(accuracy))\n",
    "        # print('')\n",
    "        # print('Batch Loss is     ', loss)\n",
    "        # print('')        \n",
    "\n",
    "        running_loss.append(loss.item())\n",
    "        running_acc.append(np.asarray(acc_).mean())\n",
    "\n",
    "        b += 1\n",
    "\n",
    "        #If training phase, send loss backwards so model can 'learn'\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            torch.no_grad()\n",
    "\n",
    "    total_batch_loss = np.asarray(running_loss).mean()\n",
    "    total_batch_acc = np.asarray(running_acc).mean()\n",
    "\n",
    "    pprint(\"{} loss is {} \".format(phase, total_batch_loss))\n",
    "    pprint(\"{} accuracy is {} \".format(phase, total_batch_acc))\n",
    "\n",
    "\n",
    "    return total_batch_loss, total_batch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set-up empty lists to improve performance\n",
    "trn_losses = [];\n",
    "trn_acc = []\n",
    "val_losses = [];\n",
    "val_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model and display progress\n",
    "for i in tqdm(range(1, EPOCHS +1)):\n",
    "    trn_l, trn_a = fit_model(i, model, train_dl)\n",
    "    val_l, val_a = fit_model(i, model, valid_dl, phase='validation')\n",
    "    trn_losses.append(trn_l);\n",
    "    trn_acc.append(trn_a)\n",
    "    val_losses.append(val_l);\n",
    "    val_acc.append(val_a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
