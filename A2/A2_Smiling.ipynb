{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script was run from Google colab, so it was necessary to mount my Google drive to access the image files and save the \n",
    "#resulting path\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install package to unzip .rar file\n",
    "!pip install unrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip the files\n",
    "!unrar x '/content/drive/My Drive/celeba.rar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path\n",
    "PATH = '/content/celeba/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Read in the csv data\n",
    "data = pd.read_csv(PATH + 'labels.csv', delim_whitespace=True)\n",
    "#Create an index\n",
    "data.set_index('img_name', inplace=True)\n",
    "#Instead of values 1,-1 I set 0,1 (replace all -1 with 0)\n",
    "data.replace(-1,0, inplace= True)\n",
    "#Read in to pickle file\n",
    "data.to_pickle(PATH + 'data_pkl.pkl')\n",
    "\n",
    "\n",
    "# for i in ['train', 'valid']:\n",
    "#     os.mkdir(os.path.join(PATH , i))\n",
    "\n",
    "#Find the image files/names\n",
    "filenames = glob.glob(PATH + 'img/*jpg')\n",
    "#Random shuffle so avoid biased training\n",
    "shuffle = np.random.permutation(len(filenames))\n",
    "\n",
    "#Create dataframes\n",
    "training_df = pd.DataFrame()\n",
    "valid_df = pd.DataFrame()\n",
    "\n",
    "#Create seperate folders for training and validation & show progress bar\n",
    "\n",
    "#Split 4,500 image files into training folder\n",
    "for j in tqdm(shuffle[:4500]):\n",
    "    file = filenames[j].split('/')[-1]\n",
    "    training_df = training_df.append( data[data.index == file])\n",
    "    shutil.copy(PATH + 'img/' + file, PATH + 'train/' + file)\n",
    "\n",
    "#Split the remaining 500 image files into validation folder\n",
    "for j in tqdm(shuffle[4500:]):\n",
    "    file = filenames[j].split('/')[-1]\n",
    "    valid_df = valid_df.append(data[data.index == file])\n",
    "    shutil.copy(PATH +'img/'+ file, PATH + 'valid/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create csv and pickle files \n",
    "training_df.to_csv(PATH + 'train.csv')\n",
    "training_df.to_pickle((PATH + 'train.pkl'))\n",
    "\n",
    "valid_df.to_csv(PATH + 'valid.csv')\n",
    "valid_df.to_pickle(PATH + 'valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import os\n",
    "\n",
    "#Outsource computing power to Google servers to avoid computer damage\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Define a class that will load the data when called\n",
    "class Smiling_loader(Dataset):\n",
    "    def __init__(self, df, img_dir, transform = None):\n",
    "        self.dataframe = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.filename = df.index\n",
    "        self.label = df.smiling.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = Image.open(os.path.join(self.img_dir, self.filename[idx]))\n",
    "        label = self.label[idx]\n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            image = self.transform(sample['image'])\n",
    "            sample = {'image': image, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
