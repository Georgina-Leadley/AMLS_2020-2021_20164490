{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This script was run from Google colab, so it was necessary to mount my Google drive to access the image files and save the \n",
    "#resulting path\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install package to unzip .rar file\n",
    "!pip install unrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip the files\n",
    "!unrar x '/content/drive/My Drive/celeba.rar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path\n",
    "PATH = '/content/celeba/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Read in the csv data\n",
    "data = pd.read_csv(PATH + 'labels.csv', delim_whitespace=True)\n",
    "#Create an index\n",
    "data.set_index('img_name', inplace=True)\n",
    "#Instead of values 1,-1 I set 0,1 (replace all -1 with 0)\n",
    "data.replace(-1,0, inplace= True)\n",
    "#Read in to pickle file\n",
    "data.to_pickle(PATH + 'data_pkl.pkl')\n",
    "\n",
    "\n",
    "# for i in ['train', 'valid']:\n",
    "#     os.mkdir(os.path.join(PATH , i))\n",
    "\n",
    "#Find the image files/names\n",
    "filenames = glob.glob(PATH + 'img/*jpg')\n",
    "#Random shuffle so avoid biased training\n",
    "shuffle = np.random.permutation(len(filenames))\n",
    "\n",
    "#Create dataframes\n",
    "training_df = pd.DataFrame()\n",
    "valid_df = pd.DataFrame()\n",
    "\n",
    "#Create seperate folders for training and validation & show progress bar\n",
    "\n",
    "#Split 4,500 image files into training folder\n",
    "for j in tqdm(shuffle[:4500]):\n",
    "    file = filenames[j].split('/')[-1]\n",
    "    training_df = training_df.append( data[data.index == file])\n",
    "    shutil.copy(PATH + 'img/' + file, PATH + 'train/' + file)\n",
    "\n",
    "#Split the remaining 500 image files into validation folder\n",
    "for j in tqdm(shuffle[4500:]):\n",
    "    file = filenames[j].split('/')[-1]\n",
    "    valid_df = valid_df.append(data[data.index == file])\n",
    "    shutil.copy(PATH +'img/'+ file, PATH + 'valid/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create csv and pickle files \n",
    "training_df.to_csv(PATH + 'train.csv')\n",
    "training_df.to_pickle((PATH + 'train.pkl'))\n",
    "\n",
    "valid_df.to_csv(PATH + 'valid.csv')\n",
    "valid_df.to_pickle(PATH + 'valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "import os\n",
    "\n",
    "#Outsource computing power to Google servers to avoid computer damage\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Define a class that will load the data when called\n",
    "class Smiling_loader(Dataset):\n",
    "    def __init__(self, df, img_dir, transform = None):\n",
    "        self.dataframe = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.filename = df.index\n",
    "        self.label = df.smiling.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image = Image.open(os.path.join(self.img_dir, self.filename[idx]))\n",
    "        label = self.label[idx]\n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            image = self.transform(sample['image'])\n",
    "            sample = {'image': image, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use pre-constructed model architectures accessed via urls\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "#Specify model - use vgg19 as it is most accurate\n",
    "model = models.vgg16_bn(pretrained = True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "#Change the final output layer to the number of classes required in our mdoel.\n",
    "n_inputs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 2048), nn.ReLU(), nn.Dropout(0.65),\n",
    "    nn.Linear(2048, 1024), nn.ReLU(),\n",
    "    nn.Dropout(0.6),\n",
    "    nn.Linear(1024, 512), nn.ReLU(),\n",
    "    nn.Linear(512, 2))\n",
    "\n",
    "#Send the Model to the GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision.utils import make_grid\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "#from Models import vgg13_bn, vgg11_bn\n",
    "from imgaug import augmenters as iaa\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "#Class specifying image transforms to improve performancce of model\n",
    "class ImAugtransforms:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "            iaa.Sometimes(0.3, iaa.GaussianBlur(sigma=(0, 2.0))),\n",
    "            iaa.Affine(rotate=(-30, 30), mode='symmetric'),\n",
    "            iaa.Sometimes(0.25,\n",
    "                          iaa.OneOf([iaa.Dropout(p=(0, 0.1)),\n",
    "                                     iaa.CoarseDropout(0.1, size_percent=0.5)])),\n",
    "            iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        return self.aug.augment_image(img)\n",
    "\n",
    "#More transformations\n",
    "train_trns = transforms.Compose([\n",
    "    ImAugtransforms(),\n",
    "    lambda x: PIL.Image.fromarray(x),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    #transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #transforms.RandomGrayscale(p=0.35),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_trns = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
